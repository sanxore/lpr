\chapter*{Annexe A3 : L'erreur Out-Of-Bag et Importance des variables}
\paragraph{L'erreur Out Of Bag:}
	Il s'agit d'une procédure permettant de fournir un estimateur de l'erreur ${E[(\hat{e}(x)-Y)^2]}$ en régression. De tels estimateurs sont souvent construits à l'aide de méthode apprentissage-validation ou validation croisée. L'avantage de la procédure Out Of Bag (OOB) est qu'elle ne nécessite pas de découper
	l'échantillon. Elle utilise le fait que les arbres sont construits sur des estimateurs agrégés et que,
	par conséquent, ils n'utilisent pas toutes les observations de l'échantillon d'apprentissage. Étant donné une observation ${(X_w,Y_w)}$ de $L_n$, on désigne par ${\omega_B}$ l'ensemble des arbres de la forêt qui
	ne contiennent pas cette observation dans leur échantillon bootstrap. Pour estimer, la prévision de
	la forêt sur ${Y_w}$ on agrège uniquement ces arbres là :
	\begin{center}
	$\hat{Y}_w = \frac{1}{|\omega_B|} \sum_{i \in \omega_B} ê(X_w,\theta_i)$
	\end{center}
\paragraph{L'importance des variables:}
	L'inconvénient des méthodes d'agrégation est que le modèle construit est difficilement interprétable, on parle souvent d'aspect boite noire.
	pour ce type de méthodes. Pour le modèle de forêts aléatoires que nous venons de présenter,
	Breiman\cite{BREI01} propose une mesure qui permet de quantifier l'importance des variables $X_j$, j=1,...,p dans le modèle.
	On désigne par $OOB_k$ l'échantillon Out Of Bag associé au \textit{k}$^{ème}$ arbre de la forêt. Cet échantillon est formé par les observations qui ne figurent pas dans le \textit{k}$^{ème}$ échantillon bootstrap. On note $E_{OOB_k}$ l'erreur de prédiction de l'arbre $ê(.,\theta_k)$ mesurée sur cet échantillon :
	\begin{center}
	$E_{OOB_k} = \frac{1}{|OOB_k|} \sum_{i \in OOB_k} (ê(X_i,\theta_k) -Y_i)^2.$
	\end{center}
	On désigne maintenant par $OOB_{k}^{j}$ l'échantillon $OOB_k$ dans lequel on a perturbé aléatoirement
	les valeurs de la variable \textit{j} et par $E_{OOB_{k}^{j}}$ l'erreur de prédiction de l'arbre $ê(.,\theta_k)$ mesurée sur cet échantillon :
	\begin{center}
		$E_{OOB_{k}^{j}} = \frac{1}{|OOB_{k}^{j}|} \sum_{i \in OOB_{k}^{j}} (ê(X_{i}^{j},\theta_k) -Y_i)^2.$
	\end{center}	
	où les $X_{i}^{j}$ désignent les observations perturbées de $OOB_{k}^{j}$. Empiriquement, si la \textit{j}$^{ème}$ variable joue un rôle déterminant dans la construction de l'arbre $ê(.,\theta_k)$, alors une permutation de ces valeurs \textit{j} dégradera fortement l'erreur. La différence d'erreur $E_{OOB_{k}^{j}}$ - $E_{OOB_k}$ sera alors élevée. L'importance de la \textit{j}$^{ème}$ variable sur la forêt est mesurée en moyennant ces différences d'erreurs sur tous les arbres :
	\begin{center}
	${Imp(X_j) = \frac{1}{B} \sum_{k=1}^{B} (E_{OOB_{k}^{j}} - E_{OOB_k}) }$
	\end{center}